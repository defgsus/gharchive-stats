{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "011a9711",
   "metadata": {},
   "source": [
    "Hi there.\n",
    "\n",
    "This notebook is analyzing the timelines of repo-push-events to find the ones that seems to be updated regularily by a cronjob.\n",
    "\n",
    "It requires:\n",
    "- downloading the data from gharchive.org\n",
    "- processing it with `export.py`\n",
    "- exporting that processed data to elasticsearch\n",
    "- further crunching it with `proc.py`\n",
    "- and finally running this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa21751",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "from typing import List, Tuple, Optional, Union\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "from elastipy import Search, query, connections\n",
    "from tqdm import tqdm\n",
    "\n",
    "pd.options.plotting.backend = \"plotly\"\n",
    "plotly.templates.default = \"plotly_dark\"\n",
    "\n",
    "connections.set(\"default\", {\"timeout\": 60})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b0f05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "spectra = (\n",
    "    pd.read_csv(\"../cache/automated-commits/spectra-s28.csv\")\n",
    "    .set_index(\"repo\")\n",
    ")\n",
    "spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ea7245",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_spectra = spectra.loc[\n",
    "    np.isnan(spectra).sum(axis=1) < .2 * spectra.shape[1]\n",
    "]\n",
    "print(f\"specta {spectra.shape[0]}, cleaned {cleaned_spectra.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226454b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_cleaned_timelines():\n",
    "    timelines = (\n",
    "        pd.read_csv(\"../cache/automated-commits/timelines.csv\")\n",
    "        .set_index(\"repo\")\n",
    "    )\n",
    "    cleaned_timelines = timelines.loc[cleaned_spectra.index]\n",
    "    cleaned_timelines = cleaned_timelines.loc[\n",
    "        (cleaned_timelines > 0).sum(axis=1) > 40\n",
    "    ]\n",
    "    return cleaned_timelines\n",
    "\n",
    "cache_file = Path(\"../cache/automated-commits/cleaned-timelines.csv\")\n",
    "if not cache_file.exists():\n",
    "    timelines = calc_cleaned_timelines()\n",
    "    timelines.to_csv(cache_file)\n",
    "else:\n",
    "    timelines = pd.read_csv(cache_file).set_index(\"repo\")\n",
    "\n",
    "spectra = cleaned_spectra.loc[timelines.index]\n",
    "print(\"timelines\", timelines.shape)\n",
    "print(\"spectra\", spectra.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3858ef65",
   "metadata": {},
   "source": [
    "# detect by mean and std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeab2bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tl_mean = timelines.mean(axis=1)\n",
    "tl_std = timelines.std(axis=1)\n",
    "is_automated_std = (tl_mean > .12) & (tl_std < .32)# & (tl_std > .31)\n",
    "is_automated_std.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618bfeaa",
   "metadata": {},
   "source": [
    "# detect by interval diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c1a832",
   "metadata": {},
   "outputs": [],
   "source": [
    "#shift = (timelines - timelines.shift(7, axis=1)).abs()\n",
    "#shift_mean, shift_std = shift.mean(axis=1), shift.std(axis=1)\n",
    "#px.line(shift_mean.sort_values().iloc[0:200].T.values)#plot(height=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5878da",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_automated_shift = timelines.apply(lambda c: False, axis=1)\n",
    "for i in tqdm(range(1, 29)):\n",
    "    shift = (timelines - timelines.shift(i, axis=1)).abs()\n",
    "    shift_mean, shift_std = shift.mean(axis=1), shift.std(axis=1)\n",
    "    is_automated_shift |= (tl_mean > .01) & (shift_mean < 0.15)\n",
    "\n",
    "is_automated_shift.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b893d65",
   "metadata": {},
   "source": [
    "# detect by spectrum std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c840889",
   "metadata": {},
   "outputs": [],
   "source": [
    "spectra_mean = spectra.mean(axis=1)\n",
    "spectra_std = spectra.std(axis=1)\n",
    "\n",
    "(spectra_std * spectra_mean).sort_values()[-500:-300].plot().show()\n",
    "timelines.loc[(spectra_std * spectra_mean).sort_values().index[-500:-300]].T.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0532d4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "is_automated_spectrum = (spectra_std * spectra_mean) >= .09\n",
    "is_automated_spectrum.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8675611d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "02428043",
   "metadata": {},
   "source": [
    "# combine all detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc545b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "is_automated = is_automated_shift | is_automated_std | is_automated_spectrum\n",
    "print(is_automated.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462952f4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = timelines.loc[is_automated]\n",
    "df = df.div(df.max(axis=1), axis=0)\n",
    "px.imshow(df, height=100+is_automated.sum()*15)\n",
    "#for i in range(0, df.shape[0], 150):\n",
    "#    timelines.loc[is_automated].iloc[i:i+150].T.plot().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159b57d5",
   "metadata": {},
   "source": [
    "# prepare data export\n",
    "\n",
    "## from elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf257f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "export_timelines = timelines.loc[is_automated]\n",
    "\n",
    "repo_info = (Search(\"gharchive-push-2018\")\n",
    " .terms(\"repo\", export_timelines.index.to_list())\n",
    " .agg_terms(\"repo\", field=\"repo\", size=export_timelines.shape[0])\n",
    " .metric_sum(\"all_push_events\", field=\"events\")\n",
    " .metric_sum(\"commits\", field=\"commits\")\n",
    " .metric_sum(\"distinct_commits\", field=\"distinct_commits\")\n",
    " .metric_cardinality(\"push_users\", field=\"user\")\n",
    " .metric_cardinality(\"refs\", field=\"ref.keyword\")\n",
    " \n",
    " .execute().df()\n",
    " .set_index(\"repo\")\n",
    " .rename({\"repo.doc_count\": \"push_events\"}, axis=1)\n",
    ")\n",
    "\n",
    "df = (Search(\"gharchive-watch-2018\")\n",
    " .terms(\"repo\", export_timelines.index.to_list())\n",
    " .agg_terms(\"repo\", field=\"repo\", size=export_timelines.shape[0])\n",
    " .metric_cardinality(\"users\", field=\"user\")\n",
    " .execute().df()\n",
    " .set_index(\"repo\")\n",
    ")\n",
    "\n",
    "repo_info[\"stars\"] = df[\"repo.doc_count\"]\n",
    "repo_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afaa3ced",
   "metadata": {},
   "source": [
    "## from github api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77c302e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from src.credentials import GITHUB_TOKEN\n",
    "from github import Github, UnknownObjectException, GithubException\n",
    "github = Github(GITHUB_TOKEN)\n",
    "\n",
    "CACHE_FILE = Path(\"../cache/repo-api-cache.json\")\n",
    "repo_api_cache = dict()\n",
    "if CACHE_FILE.exists():\n",
    "    repo_api_cache = json.loads(CACHE_FILE.read_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8649850",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, name in enumerate(tqdm(repo_info.index)):\n",
    "    if i % 500 == 0:\n",
    "        print(f\"rate-limit: {github.rate_limiting[0]}/{github.rate_limiting[1]}\")\n",
    "    if name not in repo_api_cache:\n",
    "        try:\n",
    "            data = github.get_repo(name).raw_data\n",
    "        except UnknownObjectException:\n",
    "            data = {\"deleted\": True}\n",
    "        except GithubException as e:\n",
    "            data = {\"exception\": e.status}\n",
    "        repo_api_cache[name] = data\n",
    "        \n",
    "CACHE_FILE.write_text(json.dumps(repo_api_cache, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b262579b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_status(name: str) -> str:\n",
    "    r = repo_api_cache[name]\n",
    "    if r.get(\"deleted\"):\n",
    "        return \"deleted\"\n",
    "    elif r.get(\"exception\"):\n",
    "        return f'code: {r[\"exception\"]}'\n",
    "    return \"active\"\n",
    "    \n",
    "repo_info[\"size\"] = repo_info.index.map(lambda n: repo_api_cache[n].get(\"size\"))\n",
    "repo_info[\"stars_today\"] = repo_info.index.map(lambda n: repo_api_cache[n].get(\"stargazers_count\"))\n",
    "repo_info[\"watchers_today\"] = repo_info.index.map(lambda n: repo_api_cache[n].get(\"watchers_count\"))\n",
    "repo_info[\"status\"] = repo_info.index.map(map_status)\n",
    "repo_info[\"name\"] = repo_info.index.map(lambda n: repo_api_cache[n].get(\"name\"))\n",
    "repo_info[\"fork\"] = repo_info.index.map(lambda n: repo_api_cache[n].get(\"fork\"))\n",
    "repo_info[\"created_at\"] = repo_info.index.map(lambda n: repo_api_cache[n].get(\"created_at\"))\n",
    "repo_info[\"description\"] = repo_info.index.map(lambda n: repo_api_cache[n].get(\"description\"))\n",
    "repo_info[\"homepage\"] = repo_info.index.map(lambda n: repo_api_cache[n].get(\"homepage\"))\n",
    "repo_info[\"language\"] = repo_info.index.map(lambda n: repo_api_cache[n].get(\"language\"))\n",
    "\n",
    "repo_info = repo_info.apply(lambda c: c.replace(np.nan, 0).astype(int) if c.dtype != \"object\" else c)\n",
    "repo_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165d6ec6",
   "metadata": {},
   "source": [
    "# store data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c913bd33",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#timelines.loc[is_automated].to_csv(\"../docs/data/automated-tl-1d.csv\")\n",
    "ri = repo_info.reset_index()\n",
    "data = {\n",
    "    \"columns\": ri.columns.to_list(),\n",
    "    \"rows\": [\n",
    "        row.to_dict()\n",
    "        for i, row in ri.iterrows()\n",
    "    ],\n",
    "    \"timelines\": {\n",
    "        repo: tl.to_list()\n",
    "        for repo, tl in export_timelines.replace(np.nan, 0).astype(int).iterrows()\n",
    "    }\n",
    "}\n",
    "Path(\"../docs/data/automated-2018.json\").write_text(json.dumps(data))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
